---
layout: post
title: Build a CineBot with Snowflake Native Apps and Snowflake Cortex
image: "/posts/BUILD24.jpg"
tags: [Snowflake, Streamlit]
---
I attended [Snowflake's BUILD 2024](https://www.snowflake.com/build/) conference for developers and data scientists. It focused on making use of enterprise data. 

Enterprise data is often stored in different places, unorganized, inaccessible or worse yet, stashed in a spreadsheet owned by a single team. Valuable information sits unused because employees don’t know it exists or they can’t figure out how to make use of it.

Snowflake’s Enterprise Data Warehouse acts as a central hub for all of an organization’s data. It can store structured and semi-structured data in Snowflake’s Data Cloud
Snowflake allows organizations to chat with its data using its Cortex functionality. Cortex is Snowflake's AI and ML framework. Cortex Search the feature within the Cortex tool that uses semantic lookup and vector search to power an AI-driven chat interface.
An organization can build a chat application using Snowflake Native Apps. The application can be used privately or externally. A Snowflake Native App can run securely within a customer’s Snowflake account or the Snowflake Native App can be made publicly available through the Snowflake Marketplace 
I see use cases for this technology frequently. When I worked for Colorado’s Department of Public Health and Environment, I wanted to store public data about health and environment in Snowflake and chat with it to ask questions like: 
+ How has air quality in Larimer County affected asthma cases since the Alexander Mountain Fire?
+ What was the cancer rate in counties that surround the Rocky Flats Plant prior to EPA clean up efforts and what is the cancer rate now?
+ What is the most frequent injury for children in Colorado's cities compared to injuries in rural areas?

The [Build a CineBot with Snowflake Native Apps and Snowflake Cortex project](https://quickstarts.snowflake.com/guide/build-a-cinebot-with-snowflake-native-apps-and-cortex/index.html?index=..%2F..index#0) is a good starting point and learning exercise. 
Snowflake has a public AWS S3 bucket with [movie data](https://www.kaggle.com/datasets/mehmetisik/movies-metadata) from a dataset provided by Kaggel. The lab demonstrates how to load the data from AWS into Snowflake and then query the dataset in natural language using Cortex Search. Streamlit is used to provide a user-friendly UI. 
I tried working through the lab using just the Quickstart Guide, but found some parts unclear. Following along with the recording gave me a much deeper understanding. In this blog, I’ll share what I learned and provide a step-by-step guide to setting up the project.

One key point to note is that this project requires two distinct roles to function properly: one for creating the Cine-bot app and another for using it. The NACTX (Native App Cortex) Role acts as the provider or maker of the app, handling its development and deployment. Meanwhile, the NAC (Native App Customer) role serves as the user of the app, enabling interaction and utilization within the Snowflake ecosystem.

The recorded session can be found [here](https://www.snowflake.com/build/americas/agenda/?agendaPath=speakers/3388495).

##### Step 1
Follow the Overview Section of the [Quickstart Guide](https://quickstarts.snowflake.com/guide/build-a-cinebot-with-snowflake-native-apps-and-cortex/index.html?index=..%2F..index#0), set up your free account and clone the [repo](https://github.com/Snowflake-Labs/sfguide-build-chatbot-with-snowflake-native-app-snowflake-cortex) and sign up for a trial account and clone the repo.
##### Step 2
The Snowflake interface shown in the picture below is called “Snowsight.” Click the Projects icon, represented by a command prompt symbol, in the left navigation bar. Then click on the plus sign in the top right and select SQL worksheet. A tab within the Snowsight will open. The tab will have the date. Click the three dots to the right of the date and rename it to Cine_bot lab. 
![New SQL Script](1_new_sql_script.jpg)
##### Step 3
A worksheet in Snowsight is an interactive environment where users can write, execute, and manage SQL or Python queries to interact with Snowflake data and applications. Click on the worksheets tab and you should see a blank worksheet with the name of Cine_bot lab and the role of ACCOUNTADMIN selected
![Blank Project](2_beginning_the_project.jpg)
##### Step 4
Find the repo that you cloned and find the file called lab_setup.sql in the scripts folder. Copy the file and paste it into the blank project. Select/highlight the first line that says “use role accountadmin;” and click the blue button with the arrow icon to execute the line. There will be a message at the bottom of the worksheet that says “Statement Executed Successfully”. 
![Running the first line](3_how_to_run_the_first_line.jpg)
##### Step 5
Now the next set of lines can be run as shown in the Native App Provider Setup section of the Quickstart guide
```sql create role if not exists nactx_role; 
grant role nactx_role to role accountadmin; 
grant create warehouse on account to role nactx_role; 
grant create database on account to role nactx_role; 
grant create application package on account to role nactx_role; grant create application on account to role nactx_role with grant option; ``` 
In this step the NACTX role (Native App Cortex Role) is created and configured to allow users with the accountadmin role to automatically inherit all its privileges and permissions. As a reminder, the NACTX role is the creator, publisher and distributor of the app. Which is why the next 4 lines give that role the ability to create a warehouse, a database and to create an application.

##### Step 6
The next bit of code creates the CORTEX_APP database to store application files. When building a native application, you need a database to hold all the artifacts that define the app—such as the Streamlit file, setup file, and manifest file (these are all in the repo that was cloned earlier), which specify what the app is and how it functions upon installation. The database is created as CORTEX_APP to provide a dedicated space for storing the required files, serving as the repository for all artifacts needed to create the native app package. Run the following lines:
```
use role nactx_role;
create database if not exists cortex_app;
create schema if not exists cortex_app.napp;
create stage if not exists cortex_app.napp.app_stage;
create warehouse if not exists wh_nap with warehouse_size='xsmall';
```
These lines create a schema, a database and a stage.
*Definitions:*
Schema = A logical grouping of database objects (like tables, views, and stages) within a database. It helps organize and manage related objects.
Stage = A temporary or permanent location in Snowflake used to store files for loading data into or unloading data from a database. It can be internal (within Snowflake) or external (e.g., S3 or Azure).
Warehouse = A compute resource in Snowflake that processes queries. It provides the necessary power to run SQL operations like data loading, querying, or transformations.

The CORTEX_APP warehouse size is x-small because managing application artifacts (e.g., setup files, manifest, and scripts) and creating the native app package are lightweight tasks. These tasks typically require minimal compute resources, so an x-small warehouse is sufficient. 

`"Warehouse WH_NAP successfully created.` will be displayed in the console after running the code.
#### Create NAC role and Grant Privileges
##### Step 7
To set the foundation for the user side, the ACCOUNTADMIN role is used to create a role called NAC (Native App Customer). The NACTX role is the creator of the app, the NAC is the user of the app, or the consumer.  

The warehouse, database, and application created under the NACTX_ROLE (provider role) are used to develop, package, and distribute the Snowflake Native Application. These resources are managed by the provider and contain all the necessary artifacts, such as the setup files, manifest, and application logic, to define and deploy the native app.

In contrast, the warehouse, database, and application created under the NAC role (consumer role) are for consuming and interacting with the deployed application. These resources enable the consumer to run the application, access its data, and utilize the functionality provided by the native app without direct access to the underlying application code or architecture.

In essence, the NACTX_ROLE resources focus on creating and managing the app, while the NAC role resources focus on using and interacting with the app.
Run these lines:
```
use role accountadmin;
create role if not exists nac;
grant role nac to role accountadmin;
grant create warehouse on account to role nac;
grant create database on account to role nac;
grant create application on account to role nac;
```
#### Create Consumer Test Data Database and Load Data
##### Step 8
The next set of lines create a consumer data database and load data to simulate the Snowflake consumer account. This process involves setting up a database to store the movie data that will be used to feed into the Snowflake Cortex service. Think of it as creating a database to house the movie data that we will feed into the Snowflake Cortex service.
```
use role nac;
create warehouse if not exists wh_nac with warehouse_size='medium';
create database if not exists movies;
create schema if not exists movies.data;
use schema movies.data;
```
The consumer warehouse size is medium because it is used to process larger-scale operations, such as running the native app, handling consumer data, and executing queries or tasks related to the application. This ensures adequate resources for efficient performance when interacting with large datasets.

##### Step 9
The lines below create a stage named MY_STAGE in the MOVIES.DATA schema, pointing to an S3 bucket to access the movies_metadata.csv file, with directory listing enabled and automatic metadata updates for any changes in the S3 location.
```
CREATE STAGE MOVIES.DATA.MY_STAGE
URL='s3://sfquickstarts/vhol_build_2024_native_app_cortex_search/movies_metadata.csv'
DIRECTORY = (
ENABLE = true
AUTO_REFRESH = true);
```
`Stage area MY_STAGE successfully created` will be displayed in the console
After executing the lines, confirm that things are in order. Click on the data icon in the left nav menu of the Snowsight UI. There should be a database called MOVIES. Within that database a schema named DATA should exist. There should be data called DATA. There should be a stage called MY_STAGE pointing to the S3 bucket. Don’t worry if the stage appears to be empty. A stage does not physically store files; it is a reference to the external storage location. Files are accessed from the S3 bucket dynamically when needed.

![Confirming the objects are set up in the database](3_confirm_database_data_and_stage.png)

To navigate back to the SQL file that we’ve been working with, click on the projects icon that looks like the command prompt icon. Then click on the project called cine_bot.

The following lines define the file format for loading data into Snowflake. This specifies how the data is structured, including details such as whether it is a CSV file, the delimiter used (e.g., comma or tab), and other formatting options.
```
CREATE FILE FORMAT MOVIES.DATA.CSV_FILE_FORMAT
	TYPE=CSV
    SKIP_HEADER=1
    FIELD_DELIMITER=','
    TRIM_SPACE=TRUE
    FIELD_OPTIONALLY_ENCLOSED_BY='"'
    REPLACE_INVALID_CHARACTERS=TRUE
    DATE_FORMAT=AUTO
    TIME_FORMAT=AUTO
    TIMESTAMP_FORMAT=AUTO; 
```
Execute the lines and there will be a status message in the console that says “File format CSV_FILE_FORMAT successfully created.”
##### Step 10
The Create Table step defines a table to store the movie metadata. The structure of the table is outlined in the lines below. Each column corresponds to a field in the CSV file called [Kaggle Movies Metadata] (https://www.kaggle.com/datasets/mehmetisik/movies-metadata). These columns match the dataset.
```
CREATE TABLE movies.data.movies_metadata (
    adult BOOLEAN,
    belongs_to_collection VARCHAR,
    budget NUMBER(38, 0),
    genres VARCHAR,
    homepage VARCHAR,
    id NUMBER(38, 0),
    imdb_id VARCHAR,
    original_language VARCHAR,
    original_title VARCHAR,
    overview VARCHAR,
    popularity VARCHAR,
    poster_path VARCHAR,
    production_companies VARCHAR,
    production_countries VARCHAR,
    release_date DATE,
    revenue NUMBER(38, 0),
    runtime NUMBER(38, 1),
    spoken_languages VARCHAR,
    status VARCHAR,
    tagline VARCHAR,
    title VARCHAR,
    video BOOLEAN,
    vote_average NUMBER(38, 1),
    vote_count NUMBER(38, 0)
);
```
##### Step 11
The code below copies data from the stage into the table. It retrieves the data from the S3 bucket and loads it into the table created earlier.
```
COPY INTO MOVIES.DATA.MOVIES_METADATA
FROM  @my_stage FILE_FORMAT = (FORMAT_NAME = CSV_FILE_FORMAT) ON_ERROR = CONTINUE;
```
Run an SQL query to confirm that the table is usable. This line can be run below the last line that was executed
``` SELECT * FROM movies.data.movies.metadata```
![SQL Query To Ensure Table Is Available ](4_SQL_query_to_ensure_table_is_available.png)
 ##### Step 12
The lines below create a table called MOVIES_RAW, which includes only a subset of columns from MOVIES_METADATA. Not all columns are necessary for the chatbot's functionality. The overview column will be used by the chatbot to generate recommendations. All fields are cast as strings to support chunking, using Snowflake's Snowpark library and text-splitting logic, which breaks large text data, like the overview field, into smaller, more manageable chunks.
```
CREATE OR REPLACE TABLE movies_raw AS 
SELECT 
    title, 
    budget::string AS budget, 
    overview, 
    popularity, 
    release_date::string AS release_date, 
    runtime::string AS runtime 
FROM movies.data.movies_metadata;
```
Once again it makes sense to run a query to ensure that the data in the subset is usable
```SELECT title, budget FROM movies.data.movies_metadata WHERE budget > 200000000 ORDER BY budget DESC;```
![Query of the subset table](5_query_of_the_cleaned_up_table.png)
#### Create Application Package
##### Step 13
In an earlier step the role was switched to NAC, the consumer role. The code below switches the role back to NACTX to create an empty application package. This package functions similarly to a database, serving as a container for all application artifacts. The data from CORTEX_APP will be added to the CORTEX_APP_PKG package:
```
USE ROLE nactx_role;
CREATE APPLICATION PACKAGE cortex_app_pkg;
```
##### Step 14
This step will not require you to run anything in the SQL script. In this step the Application Package will be created. An application package in Snowflake is a container that holds all the files and resources needed to create and share a native app including scripts, manifests, and user interface components. It allows the app to be securely installed and used in a consumer’s Snowflake account without revealing the app’s internal code.
This stage is where artifacts are uploaded to. The artifacts make up the native app itself. 
 ‘Select Warehouse' and choose ‘WH_NAP' for the Warehouse
![ ‘Select Warehouse' and choose ‘WH_NAP' for the Warehouse](5_query_of_the_cleaned_up_table.png)
Click on the ‘+ Files' button in the top right corner
Browse to the location of the cloned or downloaded Github repo and find the ‘/app/' folder
Select all 3 files; setup.sql, manifest.yml, and readme.md
Click the ‘Upload' button
Click on the ‘+ Files' button in the top right corner 
Browse to the location of the cloned or downloaded Github repo and find the  ‘/src/' folder
Select both files; ui.py and environment.yaml
Click the ‘Upload' button
The ui.py script builds a user interface with Streamlit to interact with a movie recommendation chatbot. 
`from snowflake.snowpark.context import get_active_session`
In ui.py, the import statement (above) retrieves the active Snowflake session, which acts as the connection between the Streamlit Cine_bot app and the data loaded into Snowflake's database environment. This data, originating from the Kaggle dataset stored in the AWS S3 Bucket, is accessed through the session. The session object provided by the get_active_session function allows the app to execute SQL queries and interact with the data.
The `query_cortex_search_service` function in ui.py interacts with Snowflake's Cortex search services. This is what allows Snowflake Cortex's retrieval-augmented generation (RAG) capabilities to answer movie-related questions. It will pull data from the MOVIES.DATA database. 
It’s important to note that Snowflake Cortex operates only on the data loaded into the Snowflake environment. The dataset consists of movies released on or before July 2017. It cannot retrieve information about movies outside the dataset. If you want the app to include logic to use Chat GPT to return similar information as the dataset, you can do so by setting up a custom integration to [OpenAI](https://quickstarts.snowflake.com/guide/getting_started_with_generative_ai_snowflake_external_functions/index.html?utm_source=chatgpt.com#0)






##### Step 15 
Return to your project called Cine_bot using the Snowsight UI. Execute this line in the lab_setup.sql 
`alter application package cortex_app_pkg add version v1 using @cortex_app.napp.app_stage;`
The console will say “Version 'V1' of application package 'CORTEX_APP_PKG' created successfully.”
##### Step 16
The `grant install, develop on application package cortex_app_pkg to role nac;` command explicitly grants the nac role both the ability to install the application package in its account and the authority to develop it. This means that users with the nac role are fully authorized to use and modify the application package.

#### Install App as the Consumer
##### Step 17
`use role nac;`
`create application cortex_app_instance from application package cortex_app_pkg using version v1;`
This line of code creates an application instance named `cortex_app_instance` from a specific version of an application package in Snowflake, `cortex_app_pkg`, which was created in step 13. By specifying version `v1`, the instance is built from a controlled set of application artifacts and logic, ensuring consistency. The`cortex_app_instance` acts as a deployed version of the application, ready for installation, configuration, and execution within the Snowflake environment. This instance is accessible and usable by users assigned to the NAC role
After running the command, the console will confirm the successful creation of the application instance. The instance is now ready to interact with the consumer's data.
##### Step 18
The following lines give the application instance access to the consumer's database, schema, and table to read and process data. These privileges allow the application to read data from the movies database, movies.data schema, and movies_raw table.
```
grant all on database movies to application cortex_app_instance; 
grant all on schema movies.data to application cortex_app_instance; 
grant all on table movies.data.movies_raw to application cortex_app_instance; 
```
##### Step 19 
USAGE is a privilege specific to Snowflake. It is part of Snowflake’s access control framework, which defines permissions for users, roles, and applications to interact with objects in the Snowflake ecosystem.
grant usage on warehouse wh_nac to application cortex_app_instance;
In this line, the Snowflake native app, which is called CORTEX_APP_INSTANCE, needs compute resources to execute queries against the movie’s metadata. The warehouse, WH_NAC, is required to process queries, retrieve movie data, run search services and summarize large text fields. By granting USAGE on the warehouse to the app, the app is permitted to utilize compute resources without being granted broader access to warehouse configurations or other unrelated data.

##### Step 20


```
use role accountadmin;
GRANT IMPORTED PRIVILEGES ON DATABASE SNOWFLAKE TO APPLICATION cortex_app_instance;
```
This is a special step required to allow the native snowflake app called “Cortex_App_Instance” to utilize Cortex Functions in a consumer database. Granting the application the ability to use imported privileges associated with the shared SNOWFLAKE database allows the application to access shared data and services provided by Snowflake. Imported privileges come from shared databases, which are accessible across Snowflake accounts. This enables the application to utilize resources such as public datasets or Snowflake-managed functions, all while maintaining security and proper governance.
This setup is useful when the application requires access to shared data and functionality provided by the SNOWFLAKE database. A SNOWFLAKE database is created and maintained by Snowflake automatically in every account. The all-caps naming is a Snowflake convention, distinguishing Snowflake-created objects from user-created objects.
#### Call the chunker stored proceedure which uses the text chunk function
##### Step 21
Switch again back to the consumer role using `use role nac;`
```
call cortex_app_instance.CORE.TABLE_CHUNKER();
```
Here, the instance of the app is calling the table_chuncker function defined in line 52 of the setup_script.sql file. The core.table_chunker() procedure creates and manages a chunked version of a movies metadata table. When table_chunker is called, it dynamically runs a SQL command to create a table named movies.data.movies_metadata_chunked. This new table is populated by selecting all columns from the movies.data.movies_raw table and adding a CHUNK column. The CHUNK column is populated by the core.text_chunk function. Text_chunk then processes the movie attributes overview, title, budget, popularity, release_date, and runtime. The procedure returns the message 'Table Chunked!'. 
```
call cortex_app_instance.CORE.CREATE_CORTEX_SEARCH();
```
This method is defined in line 68 of the setup_script.sql file. The code in the definition of the create_cortex_search() stored procedure dynamically executes an SQL command using EXECUTE IMMEDIATE to create a new Cortex Search Service named movies.data.movies_recommendation_service. The service will operate on a chunk with the warehouse wh_nac. The data for this service is coming from the movies.data.movies_metadata_chunked table. The procedure returns a confirmation message: 'Search Created go to Streamlit App' so users know that the search service is ready in the Streamlit application.
##### Step 22

Now, we'll feed the chunked data into the `create cortex search` procedure:
call cortex_app_instance.CORE.CREATE_CORTEX_SEARCH();
You can open the setup_script.sql file in Visual Studio Code and see that the `table_chunker` function creates a new table named `metadata_chunked`, selecting from the raw movie table and using the `text_chunk` function. This function utilizes an imported Python library for text splitting, preparing the data for LLM operations.
The `create_cortex_search` command creates a Cortex Search Service using the `metadata_chunked` table.
This process takes approximately 14 seconds for 45,000 rows of data.
 
#### Access the Streamlit App
##### Step 23
Now that we've created the search service, we can access the Streamlit UI. Installed native apps are found under the Data tab in the side panel, specifically in the Apps area. Click on the installed app `cortex_app_instance`. Select the consumer warehouse to run the Streamlit app. The Snowflake Cinebot recommendation app will appear.
#### Using the Cinebot App
##### Step 24

The app allows you to select a Cortex search service and adjust advanced options like the LLM model. For example, you can ask: "Please recommend five movies like The Shawshank Redemption."

The app will use the search service and LLM capabilities to provide recommendations based on themes like hope, redemption, and overcoming adversity. 

Remember that in real-world applications, the provider and consumer would typically operate in separate accounts.

The possibilities for using Cortex search services and LLMs within Snowflake native apps are vast, extending far beyond movie recommendations.






